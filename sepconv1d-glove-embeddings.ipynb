{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebfa33820536994ec572e9cb64129b4acb861268"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../input/train.csv')\n",
    "test_data=pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5f67a4ba5831cc2f871e2451bd33809e38cadac"
   },
   "outputs": [],
   "source": [
    "all_text=train_data['question_text']\n",
    "all_text.append(test_data['question_text'])\n",
    "all_text=all_text.apply(lambda x:re.sub('\\n',' ',x))\n",
    "all_text=all_text.apply(lambda x:re.sub('[^a-zA-Z0-9\\s]+','',x))\n",
    "all_text=all_text.apply(lambda x:x.strip())\n",
    "all_text=all_text.apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7ecb19e850f0f00c7475b45b014ed79d0670869"
   },
   "outputs": [],
   "source": [
    "all_text_tokenized=all_text.apply(lambda x:x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c6e0922ec6635f3644cbb7c7b18c61165ce456a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "145d759711f3e24e714ada41e47775b4d00145f8"
   },
   "outputs": [],
   "source": [
    "t=Tokenizer()\n",
    "t.fit_on_texts(list(all_text_tokenized))\n",
    "encoded_text_train=t.texts_to_sequences(train_data['question_text'])\n",
    "encoded_text_test=t.texts_to_sequences(test_data['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b1ddf02dfd0a98f344a8470ea0e0f679b7198e7"
   },
   "outputs": [],
   "source": [
    "maxnumwords=70\n",
    "vocab_size=len(t.word_index)+1\n",
    "embed_size=300\n",
    "embed_matrix=np.zeros((vocab_size,embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "855b727be01d0e3cca70f4447614ab736515d5ef"
   },
   "outputs": [],
   "source": [
    "padded_text_train=pad_sequences(encoded_text_train, maxlen=maxnumwords, padding='post')\n",
    "padded_text_test=pad_sequences(encoded_text_test, maxlen=maxnumwords, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ac4ed473992e1c0b8f8684b17f5cd778ee0392a"
   },
   "outputs": [],
   "source": [
    "embed_path=\"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3bd41916e0a7fb75d5f96317e18005b8ca24370e"
   },
   "outputs": [],
   "source": [
    "embed_file = open(embed_path)\n",
    "for line in embed_file:\n",
    "    line_arr=line.strip().split(' ')\n",
    "    if line_arr[0] in t.word_index:\n",
    "        embed_matrix[t.word_index[line_arr[0]]]=np.asarray(line_arr[1:],dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "95f39e9f760726183d076b2579f63a72e64aa19d"
   },
   "outputs": [],
   "source": [
    "indices=np.arange(len(padded_text_train))\n",
    "np.random.shuffle(indices)\n",
    "x_train=padded_text_train[indices]\n",
    "y_train=np.array(train_data.loc[indices]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f2cd13907f3e2ccfebdabbbfb433a9eb539b60a"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def prec(y_true,y_pred):\n",
    "    true_positives=K.sum(K.round(K.clip(y_true*y_pred,0,1)))\n",
    "    pred_positives=K.sum(K.round(K.clip(y_pred,0,1)))\n",
    "    precision=true_positives/(pred_positives+K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def rec(y_true,y_pred):\n",
    "    true_positives=K.sum(K.round(K.clip(y_true*y_pred,0,1)))\n",
    "    possible_positives=K.sum(K.round(K.clip(y_true,0,1)))\n",
    "    recall=true_positives/(possible_positives+K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true,y_pred):\n",
    "    true_positives=K.sum(K.round(K.clip(y_true*y_pred,0,1)))\n",
    "    possible_positives=K.sum(K.round(K.clip(y_true,0,1)))\n",
    "    pred_positives=K.sum(K.round(K.clip(y_pred,0,1)))\n",
    "    precision=true_positives/(pred_positives+K.epsilon())\n",
    "    recall=true_positives/(possible_positives+K.epsilon())\n",
    "    return (2*precision*recall)/(precision+recall+K.epsilon())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f779a6fda7b8d0314e516152caed8aeaf32370a"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',patience=3)\n",
    "file_path=\"model_sepcnn1.h5\"\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_f1_score\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "079a0ce6950b8d5decfaaf2adcd040124d574574"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import Average\n",
    "from keras.layers import Multiply\n",
    "from keras.layers import Add\n",
    "from keras.layers import SeparableConv1D\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01d1b7403d3f6ccbad7d705db8a456f111a52773",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_lin_sep_cnn(vocab_size=vocab_size,embed_size=embed_size,maxnumwords=maxnumwords,\n",
    "                      embed_matrix=embed_matrix,filters=64,kernel_size=5,\n",
    "                      depth_multiplier=2,dr_rate=0.2,pool_size=3,blocks=1):\n",
    "    model=Sequential()\n",
    "    e=Embedding(vocab_size,embed_size,input_length=maxnumwords,weights=[embed_matrix],trainable=False)\n",
    "    model.add(e)\n",
    "    for _ in range(blocks):\n",
    "        model.add(Dropout(dr_rate))\n",
    "        model.add(SeparableConv1D(filters,kernel_size,depth_multiplier=depth_multiplier,activation='relu',\n",
    "                                  depthwise_initializer='random_uniform',bias_initializer='random_uniform',\n",
    "                                 padding='same'))\n",
    "        model.add(SeparableConv1D(filters,kernel_size,depth_multiplier=depth_multiplier,\n",
    "                                  depthwise_initializer='random_uniform',bias_initializer='random_uniform',\n",
    "                                 padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size))\n",
    "        \n",
    "    model.add(SeparableConv1D(2*filters,kernel_size,depth_multiplier=depth_multiplier,activation='relu',\n",
    "                              depthwise_initializer='random_uniform',bias_initializer='random_uniform',\n",
    "                             padding='same'))\n",
    "    model.add(SeparableConv1D(2*filters,kernel_size,depth_multiplier=depth_multiplier,activation='relu',\n",
    "                              depthwise_initializer='random_uniform',bias_initializer='random_uniform',\n",
    "                             padding='same'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(dr_rate))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8886e269dd185801c971a1e1c5d852efd4ad77b1"
   },
   "outputs": [],
   "source": [
    "def model_branched_sep_cnn(vocab_size=vocab_size,embed_size=embed_size,maxnumwords=maxnumwords,\n",
    "                      embed_matrix=embed_matrix,filters=64,kernel_size=5,\n",
    "                      depth_multiplier=2,dr_rate=0.2,pool_size=3,blocks=1):\n",
    "    inp=inp=Input(shape=(maxnumwords,))\n",
    "    e=Embedding(vocab_size,embed_size,weights=[embedding_matrix],trainable=False)(inp)\n",
    "    dr=SpatialDropout1D(dr_rate)(e)\n",
    "    \n",
    "    conv1=Conv1D(filters,kernel_size-2,bias_initializer='random_uniform',\n",
    "             padding='same')(dr)\n",
    "    maxpool1=MaxPooling1D(pool_size)(conv1)\n",
    "    \n",
    "    conv2=Conv1D(filters,kernel_size,bias_initializer='random_uniform',\n",
    "             padding='same')(dr)\n",
    "    maxpool2=MaxPooling1D(pool_size)(conv2)\n",
    "    \n",
    "    conv3=Conv1D(filters,kernel_size+2,bias_initializer='random_uniform',\n",
    "             padding='same')(dr)\n",
    "    maxpool3=MaxPooling1D(pool_size)(conv3)\n",
    "    \n",
    "    x=concatenate([maxpool1,maxpool2,maxpool3],axis=1)\n",
    "    x=Activation('relu')(x)\n",
    "    #x=BatchNormalization()(x)\n",
    "    for _ in range(blocks):\n",
    "        x=Dropout(dr_rate)(x)\n",
    "        x=SeparableConv1D(2*filters,kernel_size,depth_multiplier=depth_multiplier,activation='relu',\n",
    "                                  depthwise_initializer='random_uniform',bias_initializer='random_uniform',\n",
    "                                 padding='same')(x)\n",
    "        x=MaxPooling1D(pool_size)(x)\n",
    "    \n",
    "    \"\"\"x=Conv1D(filters,kernel_size,activation='relu',bias_initializer='random_uniform',\n",
    "             padding='same')(x)\"\"\"\n",
    "    x=GlobalAveragePooling1D()(x)\n",
    "    x=Dense(1,activation='sigmoid')(x)\n",
    "    model=Model(inputs=inp,outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "333f7d6d58cc7f66b6a5bc1466ec93f57afb17aa"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import adam\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.6, nesterov=False)\n",
    "Adam=adam(lr=0.0001,decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38ff382daa3a831325d2d5ecf0d92872ae8e397a"
   },
   "outputs": [],
   "source": [
    "model=model_lin_sep_cnn(filters=64,kernel_size=5,\n",
    "                     depth_multiplier=6,dr_rate=0.2,pool_size=3,blocks=3)\n",
    "\n",
    "#model=model_branched_sep_cnn(filters=32,kernel_size=5,\n",
    "                      #depth_multiplier=2,dr_rate=0.2,pool_size=3,blocks=3)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57d4ab377ab7bcdc997bfde6b35336ddec215505"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam,metrics=[f1_score,prec,rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fc7e48ad62fa0ea25166e81969565187b817217"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,validation_split=0.05,epochs=35,callbacks=[early_stop,check_point], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03dbba14a074e6a586e548bcb99269accd080a1a"
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(padded_text_test,batch_size=1024)\n",
    "pred = np.round(predictions).astype(int).reshape(predictions.shape[0],)\n",
    "sub=pd.DataFrame()\n",
    "sub['qid']=test_data['qid']\n",
    "sub['prediction']=pred\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd4c8a17c7271558a895ab27f5b453fc57d0159b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ae8f9f841597fcc7328b7ba2da4e719dae25c67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba6003974bcdb56ef2b20baa6b77d687996ccafd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57cb36b1f2827adfb58814f34e5f4db1ad552092"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bac5e446bbd4e5bc3936fafb0264464c6bf9932f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06485a136fbaca6b27dfac15782c7edacef4100d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "870f405a64d4ab79deaf711dd783497dd94d36c2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e7dcb5d143f657f07f941af40c08c38f4fda3a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92d2969acf9c238121f66e53bfd4f0a4092aa355"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f2f904394d54778c9415bb9997ff567055acd3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9457e8779f4223e52c2865948839183921670eb4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
